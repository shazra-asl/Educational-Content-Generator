{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd03384c",
   "metadata": {},
   "source": [
    "# Educational Content Generator with Fact Verification Using Generative AI\n",
    "\n",
    "## Introduction\n",
    "This project addresses a critical challenge in education: creating accurate, grade-appropriate \n",
    "educational content with verified facts. Traditional content creation is time-consuming and may \n",
    "contain outdated or inaccurate information. Our solution leverages multiple generative AI \n",
    "capabilities to automate this process while ensuring accuracy and educational value.\n",
    "\n",
    "### Problem Statement\n",
    "Teachers and educational content creators face three main challenges:\n",
    "1. Time-consuming content creation process\n",
    "2. Difficulty in verifying factual accuracy\n",
    "3. Ensuring grade-level appropriateness\n",
    "\n",
    "### Solution Overview\n",
    "Our system combines several generative AI capabilities to create an automated, reliable \n",
    "educational content generation system:\n",
    "- Google Search grounding for fact verification\n",
    "- Structured output for consistent content formatting\n",
    "- Grade-level appropriate content generation\n",
    "- Automated content quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31aceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import Markdown, display\n",
    "from typing import TypedDict, List\n",
    "from datetime import datetime\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# # Initialize Gemini client with API key\n",
    "# client = genai.Client(api_key=UserSecretsClient().get_secret(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Initialize the Gemini client\n",
    "client = genai.Client(api_key=\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472501e7",
   "metadata": {},
   "source": [
    "## Define Core Data Structures\n",
    "We create type-safe structures to handle our educational content and analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4900747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestResults(TypedDict):\n",
    "    \"\"\"Structure to hold comprehensive test results\"\"\"\n",
    "    timestamp: str\n",
    "    content_metrics: dict\n",
    "    fact_verification: dict\n",
    "    grade_level_analysis: dict\n",
    "    execution_time: float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ee555e",
   "metadata": {},
   "source": [
    "## Content Generation and Analysis Implementation\n",
    "The following section implements our core functionality for generating and analyzing educational content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed5fd314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_topic_test(topic: str):\n",
    "    \"\"\"\n",
    "    Execute the main test with comprehensive logging and analysis for a user-specified topic.\n",
    "    This function demonstrates the integration of multiple Gen AI capabilities:\n",
    "    1. Content generation with fact verification\n",
    "    2. Source grounding\n",
    "    3. Educational content analysis\n",
    "\n",
    "    Parameters:\n",
    "        topic (str): The educational subject to generate content about.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    display(Markdown(f\"# Starting {topic.title()} Education Content Test\"))\n",
    "    display(Markdown(f\"Test started at: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\"))\n",
    "\n",
    "    try:\n",
    "        # 1. Initialize Model Configuration\n",
    "        config = types.GenerateContentConfig(\n",
    "            tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "            temperature=0.2,  # Lower temperature for more factual content\n",
    "            top_p=0.8,\n",
    "            top_k=40\n",
    "        )\n",
    "\n",
    "        # 2. Generate Content\n",
    "        display(Markdown(f\"## Generating Educational Content for {topic.title()}...\"))\n",
    "        prompt = f\"\"\"Create educational content about {topic} for 7th Grade students.\n",
    "        Include:\n",
    "        - Key scientific or conceptual ideas pertinent to the topic.\n",
    "        - Real-world examples and impacts.\n",
    "        - Recent data and statistics.\n",
    "        - Age-appropriate explanations.\n",
    "        - Actionable solutions.\n",
    "\n",
    "        Ensure all facts are verified with reliable sources.\"\"\"\n",
    "        \n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=[prompt],\n",
    "            config=config\n",
    "        )\n",
    "\n",
    "        # Document the generated content and its analysis\n",
    "        display(Markdown(\"## Generated Content\"))\n",
    "        display(Markdown(response.text))\n",
    "\n",
    "        # Analyze sources and grounding\n",
    "        display(Markdown(\"## Source Analysis\"))\n",
    "        if hasattr(response, 'grounding_metadata') and response.grounding_metadata:\n",
    "            chunks = response.grounding_metadata.grounding_chunks\n",
    "            display(Markdown(\"### Verified Sources:\"))\n",
    "            for i, chunk in enumerate(chunks, 1):\n",
    "                display(Markdown(f\"\"\"\n",
    "                **Source {i}:**\n",
    "                - **Title:** {chunk.web.title}\n",
    "                - **URL:** {chunk.web.uri}\n",
    "                - **Referenced Content:** \"{chunk.text}\"\n",
    "                \"\"\"))\n",
    "        \n",
    "        # Calculate comprehensive metrics\n",
    "        results = TestResults(\n",
    "            timestamp=start_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            content_metrics={\n",
    "                \"total_length\": len(response.text),\n",
    "                \"num_paragraphs\": len(response.text.split('\\n\\n')),\n",
    "                \"reading_level_score\": calculate_reading_level(response.text)\n",
    "            },\n",
    "            fact_verification={\n",
    "                \"verified_sources\": len(response.grounding_metadata.grounding_chunks) if hasattr(response, 'grounding_metadata') and response.grounding_metadata else 0,\n",
    "                \"fact_density\": calculate_fact_density(response.text)\n",
    "            },\n",
    "            grade_level_analysis=analyze_grade_appropriateness(response.text),\n",
    "            execution_time=(datetime.now() - start_time).total_seconds()\n",
    "        )\n",
    "\n",
    "        # Display analysis results\n",
    "        display_test_results(results)\n",
    "\n",
    "    except Exception as e:\n",
    "        display(Markdown(f\"## Error During Test Execution\\n```python\\n{str(e)}\\n```\"))\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c3d19b",
   "metadata": {},
   "source": [
    "## Analysis Helper Functions\n",
    "These functions implement our educational content analysis capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "283acd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reading_level(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate approximate reading level score using a simplified formula\n",
    "    Based on average sentence length and complex word frequency.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    sentences = text.split('.')\n",
    "    avg_words_per_sentence = len(words) / len(sentences) if sentences else 0\n",
    "    complex_words = len([w for w in words if len(w) > 8])\n",
    "    return (avg_words_per_sentence * 0.39) + (complex_words / len(words) * 100 * 0.185) if words else 0\n",
    "\n",
    "def calculate_fact_density(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the density of factual statements in the text.\n",
    "    Uses linguistic markers to identify potential fact statements.\n",
    "    \"\"\"\n",
    "    fact_indicators = ['is', 'are', 'was', 'were', 'according to', 'research shows']\n",
    "    words = text.split()\n",
    "    fact_indicators_count = sum(1 for word in words if any(indicator in word.lower() for indicator in fact_indicators))\n",
    "    return fact_indicators_count / len(words) if words else 0\n",
    "\n",
    "def analyze_grade_appropriateness(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze if content is appropriate for 7th grade level.\n",
    "    Returns metrics for sentence complexity and vocabulary.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    sentences = text.split('.')\n",
    "    return {\n",
    "        \"avg_words_per_sentence\": len(words) / len(sentences) if sentences else 0,\n",
    "        \"complex_word_ratio\": len([w for w in words if len(w) > 8]) / len(words) if words else 0,\n",
    "        \"technical_terms\": identify_technical_terms(text)\n",
    "    }\n",
    "\n",
    "def identify_technical_terms(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Identify scientific/technical terms in the content.\n",
    "    Helps assess vocabulary complexity.\n",
    "    \"\"\"\n",
    "    scientific_indicators = ['carbon', 'dioxide', 'greenhouse', 'atmosphere', 'temperature']\n",
    "    return [word for word in text.lower().split() if any(term in word for term in scientific_indicators)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f01ea46",
   "metadata": {},
   "source": [
    "## Results Display Function\n",
    "This function provides a comprehensive view of the analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c177f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_test_results(results: TestResults):\n",
    "    \"\"\"Display comprehensive test results with detailed metrics\"\"\"\n",
    "    display(Markdown(f\"\"\"\n",
    "    # Test Results Summary\n",
    "    \n",
    "    ## Execution Metrics\n",
    "    - **Test Duration:** {results['execution_time']:.2f} seconds\n",
    "    - **Timestamp:** {results['timestamp']}\n",
    "    \n",
    "    ## Content Analysis\n",
    "    - **Total Length:** {results['content_metrics']['total_length']} characters\n",
    "    - **Number of Paragraphs:** {results['content_metrics']['num_paragraphs']}\n",
    "    - **Reading Level Score:** {results['content_metrics']['reading_level_score']:.2f}\n",
    "    \n",
    "    ## Fact Verification\n",
    "    - **Verified Sources:** {results['fact_verification']['verified_sources']}\n",
    "    - **Fact Density:** {results['fact_verification']['fact_density']:.2%}\n",
    "    \n",
    "    ## Grade Level Appropriateness\n",
    "    - **Average Words per Sentence:** {results['grade_level_analysis']['avg_words_per_sentence']:.1f}\n",
    "    - **Complex Word Ratio:** {results['grade_level_analysis']['complex_word_ratio']:.2%}\n",
    "    - **Technical Terms Found:** {len(results['grade_level_analysis']['technical_terms'])}\n",
    "    \"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6933d33",
   "metadata": {},
   "source": [
    "## Execution\n",
    "Let's run our educational content generator and analysis system for a user-specified topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e4dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the topic for educational content generation\n",
    "try:\n",
    "    user_topic = \"Climate Change\"  # Replace this with any topic you desire\n",
    "    execute_topic_test(user_topic)\n",
    "except Exception as e:\n",
    "    display(Markdown(f\"# Test Failed\\nError: {str(e)}\"))\n",
    "finally:\n",
    "    display(Markdown(\"# Test Execution Completed\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5a7b3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This implementation demonstrates the effective integration of multiple generative AI capabilities:\n",
    "1. Google Search grounding for fact verification\n",
    "2. Structured output generation for educational content\n",
    "3. Automated content analysis and evaluation\n",
    "\n",
    "### Key Achievements:\n",
    "- Automated generation of grade-appropriate educational content on any given topic\n",
    "- Real-time fact verification with source citations\n",
    "- Comprehensive content quality analysis\n",
    "\n",
    "### Future Improvements:\n",
    "1. Enhanced multi-subject support\n",
    "2. Interactive, user-based content customization\n",
    "3. Customizable curriculum alignment\n",
    "4. Expanded evaluation metrics\n",
    "\n",
    "### References:\n",
    "1. Gemini API Documentation\n",
    "2. Educational Content Standards\n",
    "3. Reading Level Assessment Methodologies\n",
    "\n",
    "This notebook successfully demonstrates the potential of generative AI in educational content creation,\n",
    "providing a foundation for further advancements in automated educational content generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
